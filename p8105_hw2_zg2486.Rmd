---
title: "p8105_hw2_zg2486"
output: github_document
name: Ziqi Guo
date: "2024-09-27"
---

# Problem 1

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
```

1. Read and clean the data, select and convert variables.
```{r}
subway_df = 
  read_csv(
    "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
    na = c("NA", "", ".")) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = case_match(
      entry,
     "YES" ~ TRUE,
     "NO" ~ FALSE)
    ) 
```

Variables included in this dataset are: line, station name, station latitude, station longitude, served routes (route 1 - 11), entry, vending, entrance type, and ADA compliance. I used `janitor::clean_names` to clean up column names of data after importing data file with specifying missing values, then retained 19 required variables by `select` function, lastly, converted entry variable from character to logical variable by `mutate(case_match)` function. There are 1,868 rows and 19 columns.These data are not tidy yet.

2. Answer 3 questions.
```{r eval=FALSE}
distinct_station = group_by(subway_df, station_name) %>% 
  distinct(line) 

view(distinct_station)

ada_station = filter(subway_df, ada == TRUE) %>% 
  group_by(station_name) %>% 
  distinct(line)

list(ada_distinct_station)

no_vending = filter(subway_df, vending == "NO") %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()

entrance_allow = filter(subway_df, vending == "NO") %>% 
  filter(entry == TRUE) %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()

proportion_entry = entrance_allow / no_vending
```
There are 465 distinct stations and 84 stations are ADA compliant.The proportion of station entrances / exits without vending allow entrance is 43.43%.

3. Reformat data.
```{r}
str(subway_df)

reformat_df = subway_df %>%
  mutate(route8 = as.character(route8)) %>% 
  mutate(route9 = as.character(route9)) %>% 
  mutate(route10 = as.character(route10)) %>% 
  mutate(route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route9,
    names_to = "route_number",
    values_to = "route_name")

a_train = filter(reformat_df, route_name == "A") %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()

ada_a_train = filter(reformat_df, ada == TRUE) %>% 
  filter(route_name == "A") %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()
```
There are 60 distinct stations serve the A train. There are 17 ADA compliant of the stations that serve the A train.



# Problem 2
```{r}
mr_df = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel", na = c("NA", "", "."),
  ) %>% 
  select(-starts_with("...")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(year = as.numeric(year)) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(name = "Mr") 

professor_df = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel", na = c("NA", "", ".")
  ) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(name = "Professor")

gwynnda_df = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynnda Trash Wheel", na = c("NA", "", ".")
  ) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(name = "Gwynnda")

wheel_tidy = 
  bind_rows(mr_df, professor_df, gwynnda_df) %>% 
  janitor::clean_names() %>% 
  relocate(name)

total_weight = 
  wheel_tidy %>% 
  filter(name == "Professor") %>% 
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

total_number = 
  wheel_tidy %>% 
  filter(name == "Gwynnda", month == "June", year == 2022) %>% 
  summarise(total_number = sum(cigarette_butts))

```
There are total 1,033 observations in the combined dataset, the key variables include date, weight_tons, volume_cubic_yards, plastic_bottles, and wrappers, ect. The total weight of trash collected by Professor Trash Wheel is 246.74 tons. There total number of cigarette butts collected by Gwynda in June of 2022 are 18,120.

select(litters_df, litter_number, everything())

# Problem 3
1. Import and clean data.
```{r}
bakers_df = 
  read.csv("./gbb_datasets/bakers.csv", 
           na = c("NA", "", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(baker = word(baker_name, 1)) %>% 
  select(-baker_name) %>% 
  
bakes_df = 
  read.csv("./gbb_datasets/bakes.csv",
           na = c("NA", "", ".")) %>% 
  janitor::clean_names() 

results_df = 
  read.csv("./gbb_datasets/results.csv",
           na = c("NA", "", "."),
           skip = 2) %>% 
  janitor::clean_names() 
```

2. Check vairable types and completeness and correctness across datasets. 
```{r}
str(bakers_df)
str(bakes_df)
str(results_df)

bakers_results_df =
  anti_join(results_df, bakers_df, by = c("series", "baker" ))

bakers_results = left_join(results_df, bakers_df, by = c("series", "baker" ))

final_df = 
  anti_join(bakes_df, bakers_results, by = c("series", "baker", "episode"))
```

3. Merge to create a final dataset and organize variables' order.
```{r}
final = 
  left_join(bakers_results, bakes_df, by = c("series", "baker", "episode")) 

write_csv(final, "./gbb_datasets/final.csv")
```









write_csv(final_df, "final_bakeoff_data.csv")





