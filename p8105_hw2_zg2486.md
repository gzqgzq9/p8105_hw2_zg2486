p8105_hw2_zg2486
================
2024-09-27

# Problem 1

1.  Read and clean the data, select and convert variables.

``` r
subway_df = 
  read_csv(
    "./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
    na = c("NA", "", ".")) %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(
    entry = case_match(
      entry,
     "YES" ~ TRUE,
     "NO" ~ FALSE)
    ) 
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Variables included in this dataset are: line, station name, station
latitude, station longitude, served routes (route 1 - 11), entry,
vending, entrance type, and ADA compliance. I used
`janitor::clean_names` to clean up column names of data after importing
data file with specifying missing values, then retained 19 required
variables by `select` function, lastly, converted entry variable from
character to logical variable by `mutate(case_match)` function. There
are 1,868 rows and 19 columns.These data are not tidy yet.

2.  Answer 3 questions.

``` r
distinct_station = group_by(subway_df, station_name) %>% 
  distinct(line) 

view(distinct_station)

ada_station = filter(subway_df, ada == TRUE) %>% 
  group_by(station_name) %>% 
  distinct(line)

list(ada_distinct_station)

no_vending = filter(subway_df, vending == "NO") %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()

entrance_allow = filter(subway_df, vending == "NO") %>% 
  filter(entry == TRUE) %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()

proportion_entry = entrance_allow / no_vending
```

There are 465 distinct stations and 84 stations are ADA compliant.The
proportion of station entrances / exits without vending allow entrance
is 43.43%.

3.  Reformat data.

``` r
str(subway_df)
```

    ## tibble [1,868 × 19] (S3: tbl_df/tbl/data.frame)
    ##  $ line             : chr [1:1868] "4 Avenue" "4 Avenue" "4 Avenue" "4 Avenue" ...
    ##  $ station_name     : chr [1:1868] "25th St" "25th St" "36th St" "36th St" ...
    ##  $ station_latitude : num [1:1868] 40.7 40.7 40.7 40.7 40.7 ...
    ##  $ station_longitude: num [1:1868] -74 -74 -74 -74 -74 ...
    ##  $ route1           : chr [1:1868] "R" "R" "N" "N" ...
    ##  $ route2           : chr [1:1868] NA NA "R" "R" ...
    ##  $ route3           : chr [1:1868] NA NA NA NA ...
    ##  $ route4           : chr [1:1868] NA NA NA NA ...
    ##  $ route5           : chr [1:1868] NA NA NA NA ...
    ##  $ route6           : chr [1:1868] NA NA NA NA ...
    ##  $ route7           : chr [1:1868] NA NA NA NA ...
    ##  $ route8           : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route9           : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route10          : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ route11          : num [1:1868] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ entrance_type    : chr [1:1868] "Stair" "Stair" "Stair" "Stair" ...
    ##  $ entry            : logi [1:1868] TRUE TRUE TRUE TRUE TRUE TRUE ...
    ##  $ vending          : chr [1:1868] "YES" "YES" "YES" "YES" ...
    ##  $ ada              : logi [1:1868] FALSE FALSE FALSE FALSE FALSE FALSE ...

``` r
reformat_df = subway_df %>%
  mutate(route8 = as.character(route8)) %>% 
  mutate(route9 = as.character(route9)) %>% 
  mutate(route10 = as.character(route10)) %>% 
  mutate(route11 = as.character(route11)) %>% 
  pivot_longer(
    route1:route9,
    names_to = "route_number",
    values_to = "route_name")

a_train = filter(reformat_df, route_name == "A") %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()

ada_a_train = filter(reformat_df, ada == TRUE) %>% 
  filter(route_name == "A") %>% 
  group_by(station_name) %>% 
  distinct(line) %>% 
  nrow()
```

There are 60 distinct stations serve the A train. There are 17 ADA
compliant of the stations that serve the A train.

# Problem 2

``` r
mr_df = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel", na = c("NA", "", "."),
  ) %>% 
  select(-starts_with("...")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(year = as.numeric(year)) %>% 
  mutate(sports_balls = as.integer(sports_balls)) %>% 
  mutate(name = "Mr") 

professor_df = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel", na = c("NA", "", ".")
  ) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(name = "Professor")

gwynnda_df = 
  read_excel("./202409 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynnda Trash Wheel", na = c("NA", "", ".")
  ) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(name = "Gwynnda")

wheel_tidy = 
  bind_rows(mr_df, professor_df, gwynnda_df) %>% 
  janitor::clean_names() %>% 
  relocate(name)

total_weight = 
  wheel_tidy %>% 
  filter(name == "Professor") %>% 
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

total_number = 
  wheel_tidy %>% 
  filter(name == "Gwynnda", month == "June", year == 2022) %>% 
  summarise(total_number = sum(cigarette_butts))
```

There are total `1,033` observations in the combined dataset, the key
variables include date, weight_tons, volume_cubic_yards,
plastic_bottles, and wrappers, ect. The total weight of trash collected
by Professor Trash Wheel is `246.74` tons. There total number of
cigarette butts collected by Gwynda in June of 2022 are `18,120`.

# Problem 3

``` r
bakers_df = 
  read.csv("./gbb_datasets/bakers.csv", 
           na = c("NA", "", ".")) %>% 
  janitor::clean_names() %>% 
  mutate(baker = word(baker_name, 1)) %>% 
  select(-baker_name) 
  
bakes_df = 
  read.csv("./gbb_datasets/bakes.csv",
           na = c("NA", "", ".")) %>% 
  janitor::clean_names() 

results_df = 
  read.csv("./gbb_datasets/results.csv",
           na = c("NA", "", "."),
           skip = 2) %>% 
  janitor::clean_names() 

str(bakers_df)
str(bakes_df)
str(results_df)

results_bakers_df = 
  anti_join(bakers_df,results_df, by = c("series", "baker" ))

bakers_results_df =
  anti_join(results_df, bakers_df, by = c("series", "baker" ))

bakers_results = left_join(results_df, bakers_df, by = c("series", "baker" ))

final_df1 = 
  anti_join(bakers_results, bakes_df, by = c("series", "baker", "episode"))
  
final_df2 = 
  anti_join(bakes_df, bakers_results, by = c("series", "baker", "episode"))

final = 
  left_join(bakers_results, bakes_df, by = c("series", "baker", "episode")) 

write_csv(final, "./gbb_datasets/final.csv")
```

I first use `clean_names` function to clean three data frames, and when
we check the variable names of three data frames, we see there is a
variable called `baker_name` that includes the full name of the
contestants in baker_df instead of `baker`that only includes first name
in other two data frame, which will hinder the merging of three data
frames, so we will use `mutate` function to convert full name to first
name and use `select` remove the full name column. Next, I use `str()`
to check the variable types before merging and make sure variables would
be merged are in the same type. I `anti_join` the bakers_df and
results_df first to check missing data, and then use `left_join` to
merge these two data frames. And then check the missing data in
bakers_results_df and bakes_df, and then merge them to get final data
frame that contains 3 data files. The final data frame include `1,136`
observations and `10` variables.

```
win_table = final %>% 
  filter(result == "STAR BAKER" | result == "WINNER") %>% 
  filter(series %in% c("5", "6", "7", "8", "9", "10")) %>% 
  select(- c(baker_occupation, hometown, signature_bake, show_stopper))
```

The winners have very high technical rank and they usually win the star
baker in several episodes in that season.But surprisingly, David, the
winner in season 10 never won star baker before.

``` r
viewers_df = read.csv("./gbb_datasets/viewers.csv",
                      na = c("NA", "", ".")) %>% 
  janitor::clean_names() %>% 
  head(10)

mean_s1 = mean(viewers_df[, 2], na.rm = TRUE)

mean_s5 = mean(viewers_df[, 6], na.rm = TRUE)
```

The average viewership is `2.77` in Season 1 and `10.0393` in Season 5.
